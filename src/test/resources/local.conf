include "application.conf"

test.string = "foo"
test.variable = ${?myJvmProperty}

setl.config {
  spark {
    spark.app.name = "my_app"
    spark.sql.shuffle.partitions = "1000"
  }
}

usages.config {
  spark {
    spark.app.name = "usages_app"
    spark.cassandra.connection.host = "cassandraHost"
  }
  usages = ["cassandra"]
}

context.spark.spark.sql.shuffle.partitions = 600

csv_dc_context2 {
  storage = "CSV"
  path = "src/test/resources/test_config_csv_dc_context2"
  inferSchema = "true"
  delimiter = ";"
  header = "true"
  saveMode = "Append"
}

csv_dc_context {
  storage = "CSV"
  path = "src/test/resources/test_config_csv_dc_context"
  inferSchema = "true"
  delimiter = ";"
  header = "true"
  saveMode = "Append"
}

parquet_dc_context {
  storage = "PARQUET"
  path = "src/test/resources/test_parquet_dc_context"  // must be absolute path
  table = "test_config2222"
  saveMode = "Append"
}

csv_dc_context_consumer {
  storage = "CSV"
  path = "src/test/resources/test_config_csv_dc_context_consumer"
  inferSchema = "true"
  delimiter = ";"
  header = "true"
  saveMode = "Overwrite"
}

parquet_dc_context_consumer {
  storage = "PARQUET"
  path = "src/test/resources/test_parquet_dc_context_consumer"  // must be absolute path
  saveMode = "Append"
}
